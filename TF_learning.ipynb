{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cocse/anaconda3/lib/python3.7/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# python train_mask_detector.py --dataset dataset\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 200\n",
    "BS = 32\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(\"./data_dir\"))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "\t# load the input image (224x224) and preprocess it\n",
    "\timage = load_img(imagePath, target_size=(224, 224))\n",
    "\timage = img_to_array(image)\n",
    "\timage = preprocess_input(image)\n",
    "\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "Epoch 1/200\n",
      "129/129 [==============================] - 101s 731ms/step - loss: 0.6024 - accuracy: 0.6315 - val_loss: 0.2665 - val_accuracy: 0.9497\n",
      "Epoch 2/200\n",
      "129/129 [==============================] - 89s 690ms/step - loss: 0.4194 - accuracy: 0.7301 - val_loss: 0.2035 - val_accuracy: 0.9526\n",
      "Epoch 3/200\n",
      "129/129 [==============================] - 89s 691ms/step - loss: 0.4220 - accuracy: 0.7572 - val_loss: 0.2055 - val_accuracy: 0.9449\n",
      "Epoch 4/200\n",
      "129/129 [==============================] - 90s 695ms/step - loss: 0.3822 - accuracy: 0.7880 - val_loss: 0.1855 - val_accuracy: 0.9487\n",
      "Epoch 5/200\n",
      "129/129 [==============================] - 89s 693ms/step - loss: 0.3930 - accuracy: 0.7945 - val_loss: 0.2003 - val_accuracy: 0.9352\n",
      "Epoch 6/200\n",
      "129/129 [==============================] - 92s 714ms/step - loss: 0.3660 - accuracy: 0.8449 - val_loss: 0.1559 - val_accuracy: 0.9594\n",
      "Epoch 7/200\n",
      "129/129 [==============================] - 91s 705ms/step - loss: 0.3910 - accuracy: 0.8355 - val_loss: 0.1497 - val_accuracy: 0.9642\n",
      "Epoch 8/200\n",
      "129/129 [==============================] - 90s 699ms/step - loss: 0.3818 - accuracy: 0.8457 - val_loss: 0.1842 - val_accuracy: 0.9381\n",
      "Epoch 9/200\n",
      "129/129 [==============================] - 90s 693ms/step - loss: 0.3639 - accuracy: 0.8603 - val_loss: 0.1566 - val_accuracy: 0.9468\n",
      "Epoch 10/200\n",
      "129/129 [==============================] - 91s 706ms/step - loss: 0.3676 - accuracy: 0.8566 - val_loss: 0.1457 - val_accuracy: 0.9478\n",
      "Epoch 11/200\n",
      "129/129 [==============================] - 89s 687ms/step - loss: 0.3578 - accuracy: 0.8520 - val_loss: 0.1453 - val_accuracy: 0.9516\n",
      "Epoch 12/200\n",
      "129/129 [==============================] - 89s 687ms/step - loss: 0.3510 - accuracy: 0.8516 - val_loss: 0.1557 - val_accuracy: 0.9439\n",
      "Epoch 13/200\n",
      "129/129 [==============================] - 88s 681ms/step - loss: 0.3470 - accuracy: 0.8631 - val_loss: 0.1219 - val_accuracy: 0.9613\n",
      "Epoch 14/200\n",
      "129/129 [==============================] - 89s 685ms/step - loss: 0.3430 - accuracy: 0.8553 - val_loss: 0.1093 - val_accuracy: 0.9681\n",
      "Epoch 15/200\n",
      "129/129 [==============================] - 92s 716ms/step - loss: 0.3348 - accuracy: 0.8624 - val_loss: 0.1239 - val_accuracy: 0.9565\n",
      "Epoch 16/200\n",
      "129/129 [==============================] - 95s 735ms/step - loss: 0.3402 - accuracy: 0.8540 - val_loss: 0.1227 - val_accuracy: 0.9632\n",
      "Epoch 17/200\n",
      "129/129 [==============================] - 92s 712ms/step - loss: 0.3235 - accuracy: 0.8613 - val_loss: 0.1057 - val_accuracy: 0.9632\n",
      "Epoch 18/200\n",
      "129/129 [==============================] - 93s 720ms/step - loss: 0.3120 - accuracy: 0.8607 - val_loss: 0.0971 - val_accuracy: 0.9652\n",
      "Epoch 19/200\n",
      "129/129 [==============================] - 90s 699ms/step - loss: 0.3093 - accuracy: 0.8521 - val_loss: 0.1198 - val_accuracy: 0.9565\n",
      "Epoch 20/200\n",
      "129/129 [==============================] - 90s 697ms/step - loss: 0.3043 - accuracy: 0.8504 - val_loss: 0.1338 - val_accuracy: 0.9429\n",
      "Epoch 21/200\n",
      "129/129 [==============================] - 90s 695ms/step - loss: 0.3158 - accuracy: 0.8455 - val_loss: 0.1097 - val_accuracy: 0.9516\n",
      "Epoch 22/200\n",
      "129/129 [==============================] - 89s 692ms/step - loss: 0.2914 - accuracy: 0.8596 - val_loss: 0.0971 - val_accuracy: 0.9603\n",
      "Epoch 23/200\n",
      "129/129 [==============================] - 87s 674ms/step - loss: 0.2879 - accuracy: 0.8640 - val_loss: 0.1140 - val_accuracy: 0.9420\n",
      "Epoch 24/200\n",
      "129/129 [==============================] - 88s 682ms/step - loss: 0.2852 - accuracy: 0.8567 - val_loss: 0.0959 - val_accuracy: 0.9613\n",
      "Epoch 25/200\n",
      "129/129 [==============================] - 88s 684ms/step - loss: 0.2926 - accuracy: 0.8635 - val_loss: 0.1100 - val_accuracy: 0.9526\n",
      "Epoch 26/200\n",
      "129/129 [==============================] - 90s 697ms/step - loss: 0.2790 - accuracy: 0.8615 - val_loss: 0.1176 - val_accuracy: 0.9516\n",
      "Epoch 27/200\n",
      "129/129 [==============================] - 88s 684ms/step - loss: 0.2881 - accuracy: 0.8566 - val_loss: 0.1071 - val_accuracy: 0.9584\n",
      "Epoch 28/200\n",
      "129/129 [==============================] - 87s 673ms/step - loss: 0.2982 - accuracy: 0.8599 - val_loss: 0.1130 - val_accuracy: 0.9555\n",
      "Epoch 29/200\n",
      "129/129 [==============================] - 87s 674ms/step - loss: 0.2894 - accuracy: 0.8648 - val_loss: 0.1073 - val_accuracy: 0.9574\n",
      "Epoch 30/200\n",
      "129/129 [==============================] - 87s 673ms/step - loss: 0.2894 - accuracy: 0.8501 - val_loss: 0.1264 - val_accuracy: 0.9410\n",
      "Epoch 31/200\n",
      "129/129 [==============================] - 88s 681ms/step - loss: 0.2735 - accuracy: 0.8658 - val_loss: 0.1029 - val_accuracy: 0.9555\n",
      "Epoch 32/200\n",
      "129/129 [==============================] - 86s 667ms/step - loss: 0.2810 - accuracy: 0.8605 - val_loss: 0.0892 - val_accuracy: 0.9574\n",
      "Epoch 33/200\n",
      "129/129 [==============================] - 86s 667ms/step - loss: 0.2727 - accuracy: 0.8758 - val_loss: 0.1050 - val_accuracy: 0.9584\n",
      "Epoch 34/200\n",
      "129/129 [==============================] - 86s 665ms/step - loss: 0.2753 - accuracy: 0.8657 - val_loss: 0.0860 - val_accuracy: 0.9662\n",
      "Epoch 35/200\n",
      "129/129 [==============================] - 87s 675ms/step - loss: 0.2629 - accuracy: 0.8651 - val_loss: 0.1006 - val_accuracy: 0.9662\n",
      "Epoch 36/200\n",
      "129/129 [==============================] - 88s 683ms/step - loss: 0.2660 - accuracy: 0.8664 - val_loss: 0.0863 - val_accuracy: 0.9681\n",
      "Epoch 37/200\n",
      "129/129 [==============================] - 87s 675ms/step - loss: 0.2610 - accuracy: 0.8658 - val_loss: 0.0940 - val_accuracy: 0.9642\n",
      "Epoch 38/200\n",
      "129/129 [==============================] - 90s 694ms/step - loss: 0.2610 - accuracy: 0.8668 - val_loss: 0.1052 - val_accuracy: 0.9613\n",
      "Epoch 39/200\n",
      "129/129 [==============================] - 89s 688ms/step - loss: 0.2799 - accuracy: 0.8638 - val_loss: 0.1140 - val_accuracy: 0.9545\n",
      "Epoch 40/200\n",
      "129/129 [==============================] - 86s 668ms/step - loss: 0.2663 - accuracy: 0.8658 - val_loss: 0.0897 - val_accuracy: 0.9652\n",
      "Epoch 41/200\n",
      "129/129 [==============================] - 87s 670ms/step - loss: 0.2885 - accuracy: 0.8559 - val_loss: 0.1535 - val_accuracy: 0.9371\n",
      "Epoch 42/200\n",
      "129/129 [==============================] - 87s 671ms/step - loss: 0.2805 - accuracy: 0.8632 - val_loss: 0.1048 - val_accuracy: 0.9671\n",
      "Epoch 43/200\n",
      "129/129 [==============================] - 88s 678ms/step - loss: 0.2698 - accuracy: 0.8568 - val_loss: 0.0875 - val_accuracy: 0.9691\n",
      "Epoch 44/200\n",
      "129/129 [==============================] - 88s 680ms/step - loss: 0.2653 - accuracy: 0.8687 - val_loss: 0.1182 - val_accuracy: 0.9594\n",
      "Epoch 45/200\n",
      "129/129 [==============================] - 88s 682ms/step - loss: 0.2660 - accuracy: 0.8683 - val_loss: 0.0907 - val_accuracy: 0.9662\n",
      "Epoch 46/200\n",
      "129/129 [==============================] - 88s 684ms/step - loss: 0.2674 - accuracy: 0.8686 - val_loss: 0.0933 - val_accuracy: 0.9671\n",
      "Epoch 47/200\n",
      "129/129 [==============================] - 90s 694ms/step - loss: 0.2569 - accuracy: 0.8624 - val_loss: 0.1046 - val_accuracy: 0.9555\n",
      "Epoch 48/200\n",
      "129/129 [==============================] - 89s 693ms/step - loss: 0.2610 - accuracy: 0.8730 - val_loss: 0.0935 - val_accuracy: 0.9613\n",
      "Epoch 49/200\n",
      "129/129 [==============================] - 87s 676ms/step - loss: 0.2749 - accuracy: 0.8686 - val_loss: 0.0937 - val_accuracy: 0.9700\n",
      "Epoch 50/200\n",
      "129/129 [==============================] - 87s 673ms/step - loss: 0.2576 - accuracy: 0.8653 - val_loss: 0.1056 - val_accuracy: 0.9662\n",
      "Epoch 51/200\n",
      "129/129 [==============================] - 86s 662ms/step - loss: 0.2749 - accuracy: 0.8615 - val_loss: 0.1000 - val_accuracy: 0.9681\n",
      "Epoch 52/200\n",
      "129/129 [==============================] - 87s 671ms/step - loss: 0.2674 - accuracy: 0.8642 - val_loss: 0.0925 - val_accuracy: 0.9671\n",
      "Epoch 53/200\n",
      "129/129 [==============================] - 87s 673ms/step - loss: 0.2508 - accuracy: 0.8676 - val_loss: 0.0879 - val_accuracy: 0.9652\n",
      "Epoch 54/200\n",
      "129/129 [==============================] - 87s 677ms/step - loss: 0.2535 - accuracy: 0.8615 - val_loss: 0.0862 - val_accuracy: 0.9662\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 90s 697ms/step - loss: 0.2697 - accuracy: 0.8610 - val_loss: 0.0999 - val_accuracy: 0.9594\n",
      "Epoch 56/200\n",
      "129/129 [==============================] - 87s 674ms/step - loss: 0.2401 - accuracy: 0.8803 - val_loss: 0.0890 - val_accuracy: 0.9691\n",
      "Epoch 57/200\n",
      "129/129 [==============================] - 85s 662ms/step - loss: 0.2441 - accuracy: 0.8785 - val_loss: 0.0855 - val_accuracy: 0.9681\n",
      "Epoch 58/200\n",
      "129/129 [==============================] - 89s 689ms/step - loss: 0.2681 - accuracy: 0.8655 - val_loss: 0.0876 - val_accuracy: 0.9671\n",
      "Epoch 59/200\n",
      "129/129 [==============================] - 88s 683ms/step - loss: 0.2608 - accuracy: 0.8669 - val_loss: 0.0923 - val_accuracy: 0.9613\n",
      "Epoch 60/200\n",
      "129/129 [==============================] - 88s 685ms/step - loss: 0.2577 - accuracy: 0.8639 - val_loss: 0.1009 - val_accuracy: 0.9613\n",
      "Epoch 61/200\n",
      "129/129 [==============================] - 90s 699ms/step - loss: 0.2647 - accuracy: 0.8563 - val_loss: 0.0910 - val_accuracy: 0.9662\n",
      "Epoch 62/200\n",
      "129/129 [==============================] - 88s 684ms/step - loss: 0.2452 - accuracy: 0.8855 - val_loss: 0.0960 - val_accuracy: 0.9681\n",
      "Epoch 63/200\n",
      "129/129 [==============================] - 87s 671ms/step - loss: 0.2505 - accuracy: 0.8727 - val_loss: 0.0915 - val_accuracy: 0.9700\n",
      "Epoch 64/200\n",
      "129/129 [==============================] - 86s 669ms/step - loss: 0.2470 - accuracy: 0.8787 - val_loss: 0.0973 - val_accuracy: 0.9603\n",
      "Epoch 65/200\n",
      "129/129 [==============================] - 87s 672ms/step - loss: 0.2401 - accuracy: 0.8822 - val_loss: 0.0776 - val_accuracy: 0.9749\n",
      "Epoch 66/200\n",
      "129/129 [==============================] - 87s 674ms/step - loss: 0.2505 - accuracy: 0.8724 - val_loss: 0.0808 - val_accuracy: 0.9632\n",
      "Epoch 67/200\n",
      "129/129 [==============================] - 87s 674ms/step - loss: 0.2511 - accuracy: 0.8750 - val_loss: 0.1263 - val_accuracy: 0.9574\n",
      "Epoch 68/200\n",
      "129/129 [==============================] - 86s 668ms/step - loss: 0.2374 - accuracy: 0.8853 - val_loss: 0.1662 - val_accuracy: 0.9410\n",
      "Epoch 69/200\n",
      "129/129 [==============================] - 88s 684ms/step - loss: 0.2505 - accuracy: 0.8715 - val_loss: 0.0830 - val_accuracy: 0.9681\n",
      "Epoch 70/200\n",
      "129/129 [==============================] - 88s 683ms/step - loss: 0.2560 - accuracy: 0.8751 - val_loss: 0.0888 - val_accuracy: 0.9662\n",
      "Epoch 71/200\n",
      "129/129 [==============================] - 87s 677ms/step - loss: 0.2603 - accuracy: 0.8734 - val_loss: 0.1604 - val_accuracy: 0.9381\n",
      "Epoch 72/200\n",
      "129/129 [==============================] - 87s 675ms/step - loss: 0.2445 - accuracy: 0.8753 - val_loss: 0.1046 - val_accuracy: 0.9729\n",
      "Epoch 73/200\n",
      "129/129 [==============================] - 90s 701ms/step - loss: 0.2629 - accuracy: 0.8711 - val_loss: 0.0826 - val_accuracy: 0.9710\n",
      "Epoch 74/200\n",
      "129/129 [==============================] - 88s 680ms/step - loss: 0.2473 - accuracy: 0.8814 - val_loss: 0.0808 - val_accuracy: 0.9681\n",
      "Epoch 75/200\n",
      "129/129 [==============================] - 88s 682ms/step - loss: 0.2518 - accuracy: 0.8663 - val_loss: 0.0829 - val_accuracy: 0.9662\n",
      "Epoch 76/200\n",
      "129/129 [==============================] - 86s 668ms/step - loss: 0.2558 - accuracy: 0.8748 - val_loss: 0.0903 - val_accuracy: 0.9652\n",
      "Epoch 77/200\n",
      "129/129 [==============================] - 89s 689ms/step - loss: 0.2427 - accuracy: 0.8754 - val_loss: 0.0908 - val_accuracy: 0.9632\n",
      "Epoch 78/200\n",
      "129/129 [==============================] - 87s 673ms/step - loss: 0.2475 - accuracy: 0.8743 - val_loss: 0.0851 - val_accuracy: 0.9710\n",
      "Epoch 79/200\n",
      "129/129 [==============================] - 86s 666ms/step - loss: 0.2332 - accuracy: 0.8892 - val_loss: 0.1012 - val_accuracy: 0.9613\n",
      "Epoch 80/200\n",
      "129/129 [==============================] - 85s 655ms/step - loss: 0.2573 - accuracy: 0.8682 - val_loss: 0.0791 - val_accuracy: 0.9739\n",
      "Epoch 81/200\n",
      "129/129 [==============================] - 85s 660ms/step - loss: 0.2433 - accuracy: 0.8790 - val_loss: 0.0941 - val_accuracy: 0.9632\n",
      "Epoch 82/200\n",
      "129/129 [==============================] - 86s 666ms/step - loss: 0.2550 - accuracy: 0.8737 - val_loss: 0.0811 - val_accuracy: 0.9720\n",
      "Epoch 83/200\n",
      "129/129 [==============================] - 85s 660ms/step - loss: 0.2478 - accuracy: 0.8720 - val_loss: 0.0960 - val_accuracy: 0.9584\n",
      "Epoch 84/200\n",
      "129/129 [==============================] - 85s 655ms/step - loss: 0.2542 - accuracy: 0.8735 - val_loss: 0.1139 - val_accuracy: 0.9516\n",
      "Epoch 85/200\n",
      "129/129 [==============================] - 84s 651ms/step - loss: 0.2487 - accuracy: 0.8754 - val_loss: 0.0825 - val_accuracy: 0.9671\n",
      "Epoch 86/200\n",
      "129/129 [==============================] - 85s 656ms/step - loss: 0.2427 - accuracy: 0.8668 - val_loss: 0.0881 - val_accuracy: 0.9632\n",
      "Epoch 87/200\n",
      "129/129 [==============================] - 86s 666ms/step - loss: 0.2458 - accuracy: 0.8737 - val_loss: 0.0850 - val_accuracy: 0.9700\n",
      "Epoch 88/200\n",
      "129/129 [==============================] - 88s 683ms/step - loss: 0.2471 - accuracy: 0.8708 - val_loss: 0.0793 - val_accuracy: 0.9749\n",
      "Epoch 89/200\n",
      "129/129 [==============================] - 86s 662ms/step - loss: 0.2461 - accuracy: 0.8701 - val_loss: 0.0891 - val_accuracy: 0.9768\n",
      "Epoch 90/200\n",
      "129/129 [==============================] - 88s 680ms/step - loss: 0.2392 - accuracy: 0.8788 - val_loss: 0.0848 - val_accuracy: 0.9729\n",
      "Epoch 91/200\n",
      "129/129 [==============================] - 86s 665ms/step - loss: 0.2448 - accuracy: 0.8738 - val_loss: 0.1005 - val_accuracy: 0.9623\n",
      "Epoch 92/200\n",
      "129/129 [==============================] - 87s 678ms/step - loss: 0.2466 - accuracy: 0.8683 - val_loss: 0.1099 - val_accuracy: 0.9574\n",
      "Epoch 93/200\n",
      "129/129 [==============================] - 87s 670ms/step - loss: 0.2575 - accuracy: 0.8677 - val_loss: 0.0960 - val_accuracy: 0.9623\n",
      "Epoch 94/200\n",
      "129/129 [==============================] - 87s 675ms/step - loss: 0.2353 - accuracy: 0.8843 - val_loss: 0.1017 - val_accuracy: 0.9603\n",
      "Epoch 95/200\n",
      "129/129 [==============================] - 86s 667ms/step - loss: 0.2537 - accuracy: 0.8679 - val_loss: 0.0793 - val_accuracy: 0.9710\n",
      "Epoch 96/200\n",
      "129/129 [==============================] - 87s 672ms/step - loss: 0.2449 - accuracy: 0.8774 - val_loss: 0.0819 - val_accuracy: 0.9700\n",
      "Epoch 97/200\n",
      "129/129 [==============================] - 86s 668ms/step - loss: 0.2525 - accuracy: 0.8742 - val_loss: 0.0862 - val_accuracy: 0.9671\n",
      "Epoch 98/200\n",
      "129/129 [==============================] - 87s 673ms/step - loss: 0.2402 - accuracy: 0.8787 - val_loss: 0.0823 - val_accuracy: 0.9642\n",
      "Epoch 99/200\n",
      "129/129 [==============================] - 86s 664ms/step - loss: 0.2434 - accuracy: 0.8761 - val_loss: 0.0757 - val_accuracy: 0.9710\n",
      "Epoch 100/200\n",
      "129/129 [==============================] - 85s 658ms/step - loss: 0.2468 - accuracy: 0.8708 - val_loss: 0.0717 - val_accuracy: 0.9739\n",
      "Epoch 101/200\n",
      "129/129 [==============================] - 85s 660ms/step - loss: 0.2396 - accuracy: 0.8752 - val_loss: 0.0851 - val_accuracy: 0.9700\n",
      "Epoch 102/200\n",
      "129/129 [==============================] - 87s 671ms/step - loss: 0.2484 - accuracy: 0.8673 - val_loss: 0.0977 - val_accuracy: 0.9632\n",
      "Epoch 103/200\n",
      "129/129 [==============================] - 85s 660ms/step - loss: 0.2490 - accuracy: 0.8676 - val_loss: 0.0850 - val_accuracy: 0.9671\n",
      "Epoch 104/200\n",
      "129/129 [==============================] - 87s 674ms/step - loss: 0.2397 - accuracy: 0.8747 - val_loss: 0.0990 - val_accuracy: 0.9623\n",
      "Epoch 105/200\n",
      "129/129 [==============================] - 85s 659ms/step - loss: 0.2451 - accuracy: 0.8773 - val_loss: 0.1053 - val_accuracy: 0.9613\n",
      "Epoch 106/200\n",
      "129/129 [==============================] - 84s 647ms/step - loss: 0.2512 - accuracy: 0.8657 - val_loss: 0.1230 - val_accuracy: 0.9574\n",
      "Epoch 107/200\n",
      "129/129 [==============================] - 87s 672ms/step - loss: 0.2459 - accuracy: 0.8746 - val_loss: 0.1195 - val_accuracy: 0.9555\n",
      "Epoch 108/200\n",
      "129/129 [==============================] - 85s 662ms/step - loss: 0.2496 - accuracy: 0.8702 - val_loss: 0.1130 - val_accuracy: 0.9613\n",
      "Epoch 109/200\n",
      "129/129 [==============================] - 86s 668ms/step - loss: 0.2479 - accuracy: 0.8699 - val_loss: 0.1258 - val_accuracy: 0.9497\n",
      "Epoch 110/200\n",
      "129/129 [==============================] - 88s 679ms/step - loss: 0.2458 - accuracy: 0.8695 - val_loss: 0.1030 - val_accuracy: 0.9613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "129/129 [==============================] - 87s 677ms/step - loss: 0.2413 - accuracy: 0.8803 - val_loss: 0.0993 - val_accuracy: 0.9642\n",
      "Epoch 112/200\n",
      "129/129 [==============================] - 86s 663ms/step - loss: 0.2547 - accuracy: 0.8625 - val_loss: 0.0739 - val_accuracy: 0.9710\n",
      "Epoch 113/200\n",
      "129/129 [==============================] - 86s 666ms/step - loss: 0.2427 - accuracy: 0.8816 - val_loss: 0.0920 - val_accuracy: 0.9671\n",
      "Epoch 114/200\n",
      "129/129 [==============================] - 86s 668ms/step - loss: 0.2332 - accuracy: 0.8829 - val_loss: 0.0833 - val_accuracy: 0.9720\n",
      "Epoch 115/200\n",
      "129/129 [==============================] - 85s 657ms/step - loss: 0.2429 - accuracy: 0.8764 - val_loss: 0.0833 - val_accuracy: 0.9700\n",
      "Epoch 116/200\n",
      "129/129 [==============================] - 85s 661ms/step - loss: 0.2388 - accuracy: 0.8800 - val_loss: 0.0881 - val_accuracy: 0.9700\n",
      "Epoch 117/200\n",
      "129/129 [==============================] - 85s 656ms/step - loss: 0.2502 - accuracy: 0.8581 - val_loss: 0.1131 - val_accuracy: 0.9623\n",
      "Epoch 118/200\n",
      "129/129 [==============================] - 82s 636ms/step - loss: 0.2488 - accuracy: 0.8759 - val_loss: 0.0813 - val_accuracy: 0.9720\n",
      "Epoch 119/200\n",
      "129/129 [==============================] - 83s 641ms/step - loss: 0.2400 - accuracy: 0.8800 - val_loss: 0.0951 - val_accuracy: 0.9642\n",
      "Epoch 120/200\n",
      "129/129 [==============================] - 82s 633ms/step - loss: 0.2530 - accuracy: 0.8678 - val_loss: 0.0861 - val_accuracy: 0.9681\n",
      "Epoch 121/200\n",
      "129/129 [==============================] - 83s 646ms/step - loss: 0.2466 - accuracy: 0.8709 - val_loss: 0.1108 - val_accuracy: 0.9681\n",
      "Epoch 122/200\n",
      "129/129 [==============================] - 83s 645ms/step - loss: 0.2524 - accuracy: 0.8803 - val_loss: 0.0891 - val_accuracy: 0.9691\n",
      "Epoch 123/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2401 - accuracy: 0.8757 - val_loss: 0.1079 - val_accuracy: 0.9671\n",
      "Epoch 124/200\n",
      "129/129 [==============================] - 82s 639ms/step - loss: 0.2354 - accuracy: 0.8796 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
      "Epoch 125/200\n",
      "129/129 [==============================] - 83s 643ms/step - loss: 0.2482 - accuracy: 0.8758 - val_loss: 0.1239 - val_accuracy: 0.9652\n",
      "Epoch 126/200\n",
      "129/129 [==============================] - 83s 643ms/step - loss: 0.2417 - accuracy: 0.8699 - val_loss: 0.1162 - val_accuracy: 0.9632\n",
      "Epoch 127/200\n",
      "129/129 [==============================] - 83s 643ms/step - loss: 0.2330 - accuracy: 0.8798 - val_loss: 0.1101 - val_accuracy: 0.9662\n",
      "Epoch 128/200\n",
      "129/129 [==============================] - 84s 647ms/step - loss: 0.2408 - accuracy: 0.8750 - val_loss: 0.0818 - val_accuracy: 0.9729\n",
      "Epoch 129/200\n",
      "129/129 [==============================] - 83s 644ms/step - loss: 0.2417 - accuracy: 0.8780 - val_loss: 0.0881 - val_accuracy: 0.9720\n",
      "Epoch 130/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2321 - accuracy: 0.8819 - val_loss: 0.1039 - val_accuracy: 0.9613\n",
      "Epoch 131/200\n",
      "129/129 [==============================] - 83s 642ms/step - loss: 0.2504 - accuracy: 0.8625 - val_loss: 0.0999 - val_accuracy: 0.9700\n",
      "Epoch 132/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2318 - accuracy: 0.8780 - val_loss: 0.1265 - val_accuracy: 0.9632\n",
      "Epoch 133/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2517 - accuracy: 0.8691 - val_loss: 0.0983 - val_accuracy: 0.9691\n",
      "Epoch 134/200\n",
      "129/129 [==============================] - 83s 646ms/step - loss: 0.2436 - accuracy: 0.8779 - val_loss: 0.1178 - val_accuracy: 0.9487\n",
      "Epoch 135/200\n",
      "129/129 [==============================] - 82s 639ms/step - loss: 0.2421 - accuracy: 0.8724 - val_loss: 0.1013 - val_accuracy: 0.9642\n",
      "Epoch 136/200\n",
      "129/129 [==============================] - 84s 647ms/step - loss: 0.2507 - accuracy: 0.8696 - val_loss: 0.1140 - val_accuracy: 0.9613\n",
      "Epoch 137/200\n",
      "129/129 [==============================] - 83s 644ms/step - loss: 0.2493 - accuracy: 0.8652 - val_loss: 0.1110 - val_accuracy: 0.9603\n",
      "Epoch 138/200\n",
      "129/129 [==============================] - 83s 642ms/step - loss: 0.2371 - accuracy: 0.8806 - val_loss: 0.1054 - val_accuracy: 0.9642\n",
      "Epoch 139/200\n",
      "129/129 [==============================] - 83s 642ms/step - loss: 0.2423 - accuracy: 0.8718 - val_loss: 0.1096 - val_accuracy: 0.9652\n",
      "Epoch 140/200\n",
      "129/129 [==============================] - 82s 638ms/step - loss: 0.2495 - accuracy: 0.8671 - val_loss: 0.0999 - val_accuracy: 0.9671\n",
      "Epoch 141/200\n",
      "129/129 [==============================] - 82s 638ms/step - loss: 0.2472 - accuracy: 0.8670 - val_loss: 0.1042 - val_accuracy: 0.9691\n",
      "Epoch 142/200\n",
      "129/129 [==============================] - 83s 644ms/step - loss: 0.2466 - accuracy: 0.8667 - val_loss: 0.1248 - val_accuracy: 0.9662\n",
      "Epoch 143/200\n",
      "129/129 [==============================] - 83s 643ms/step - loss: 0.2471 - accuracy: 0.8738 - val_loss: 0.1173 - val_accuracy: 0.9710\n",
      "Epoch 144/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2590 - accuracy: 0.8581 - val_loss: 0.1227 - val_accuracy: 0.9623\n",
      "Epoch 145/200\n",
      "129/129 [==============================] - 82s 636ms/step - loss: 0.2501 - accuracy: 0.8685 - val_loss: 0.1396 - val_accuracy: 0.9613\n",
      "Epoch 146/200\n",
      "129/129 [==============================] - 83s 642ms/step - loss: 0.2427 - accuracy: 0.8757 - val_loss: 0.1217 - val_accuracy: 0.9652\n",
      "Epoch 147/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2540 - accuracy: 0.8581 - val_loss: 0.1307 - val_accuracy: 0.9603\n",
      "Epoch 148/200\n",
      "129/129 [==============================] - 84s 654ms/step - loss: 0.2530 - accuracy: 0.8681 - val_loss: 0.0861 - val_accuracy: 0.9691\n",
      "Epoch 149/200\n",
      "129/129 [==============================] - 83s 641ms/step - loss: 0.2370 - accuracy: 0.8777 - val_loss: 0.1129 - val_accuracy: 0.9603\n",
      "Epoch 150/200\n",
      "129/129 [==============================] - 82s 632ms/step - loss: 0.2451 - accuracy: 0.8761 - val_loss: 0.1063 - val_accuracy: 0.9603\n",
      "Epoch 151/200\n",
      "129/129 [==============================] - 82s 634ms/step - loss: 0.2426 - accuracy: 0.8745 - val_loss: 0.1041 - val_accuracy: 0.9671\n",
      "Epoch 152/200\n",
      "129/129 [==============================] - 82s 633ms/step - loss: 0.2445 - accuracy: 0.8712 - val_loss: 0.1076 - val_accuracy: 0.9603\n",
      "Epoch 153/200\n",
      "129/129 [==============================] - 81s 629ms/step - loss: 0.2365 - accuracy: 0.8755 - val_loss: 0.0999 - val_accuracy: 0.9681\n",
      "Epoch 154/200\n",
      "129/129 [==============================] - 81s 631ms/step - loss: 0.2424 - accuracy: 0.8782 - val_loss: 0.0808 - val_accuracy: 0.9720\n",
      "Epoch 155/200\n",
      "129/129 [==============================] - 82s 632ms/step - loss: 0.2358 - accuracy: 0.8752 - val_loss: 0.1147 - val_accuracy: 0.9642\n",
      "Epoch 156/200\n",
      "129/129 [==============================] - 82s 637ms/step - loss: 0.2585 - accuracy: 0.8642 - val_loss: 0.1088 - val_accuracy: 0.9671\n",
      "Epoch 157/200\n",
      "129/129 [==============================] - 82s 639ms/step - loss: 0.2410 - accuracy: 0.8768 - val_loss: 0.1247 - val_accuracy: 0.9642\n",
      "Epoch 158/200\n",
      "129/129 [==============================] - 82s 635ms/step - loss: 0.2501 - accuracy: 0.8685 - val_loss: 0.1004 - val_accuracy: 0.9681\n",
      "Epoch 159/200\n",
      "129/129 [==============================] - 82s 637ms/step - loss: 0.2377 - accuracy: 0.8778 - val_loss: 0.1162 - val_accuracy: 0.9671\n",
      "Epoch 160/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2489 - accuracy: 0.8749 - val_loss: 0.1057 - val_accuracy: 0.9652\n",
      "Epoch 161/200\n",
      "129/129 [==============================] - 82s 638ms/step - loss: 0.2409 - accuracy: 0.8755 - val_loss: 0.1226 - val_accuracy: 0.9632\n",
      "Epoch 162/200\n",
      "129/129 [==============================] - 82s 634ms/step - loss: 0.2524 - accuracy: 0.8702 - val_loss: 0.1015 - val_accuracy: 0.9623\n",
      "Epoch 163/200\n",
      "129/129 [==============================] - 82s 633ms/step - loss: 0.2419 - accuracy: 0.8744 - val_loss: 0.1085 - val_accuracy: 0.9632\n",
      "Epoch 164/200\n",
      "129/129 [==============================] - 83s 642ms/step - loss: 0.2327 - accuracy: 0.8818 - val_loss: 0.0933 - val_accuracy: 0.9681\n",
      "Epoch 165/200\n",
      "129/129 [==============================] - 83s 646ms/step - loss: 0.2363 - accuracy: 0.8767 - val_loss: 0.1011 - val_accuracy: 0.9681\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 82s 636ms/step - loss: 0.2353 - accuracy: 0.8750 - val_loss: 0.1035 - val_accuracy: 0.9662\n",
      "Epoch 167/200\n",
      "129/129 [==============================] - 82s 633ms/step - loss: 0.2400 - accuracy: 0.8774 - val_loss: 0.1133 - val_accuracy: 0.9613\n",
      "Epoch 168/200\n",
      "129/129 [==============================] - 82s 636ms/step - loss: 0.2460 - accuracy: 0.8764 - val_loss: 0.2139 - val_accuracy: 0.9410\n",
      "Epoch 169/200\n",
      "129/129 [==============================] - 83s 639ms/step - loss: 0.2452 - accuracy: 0.8715 - val_loss: 0.1247 - val_accuracy: 0.9613\n",
      "Epoch 170/200\n",
      "129/129 [==============================] - 82s 638ms/step - loss: 0.2355 - accuracy: 0.8793 - val_loss: 0.1478 - val_accuracy: 0.9449\n",
      "Epoch 171/200\n",
      "129/129 [==============================] - 82s 633ms/step - loss: 0.2319 - accuracy: 0.8812 - val_loss: 0.1138 - val_accuracy: 0.9574\n",
      "Epoch 172/200\n",
      "129/129 [==============================] - 82s 635ms/step - loss: 0.2426 - accuracy: 0.8752 - val_loss: 0.1480 - val_accuracy: 0.9555\n",
      "Epoch 173/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2489 - accuracy: 0.8623 - val_loss: 0.1213 - val_accuracy: 0.9662\n",
      "Epoch 174/200\n",
      "129/129 [==============================] - 82s 636ms/step - loss: 0.2596 - accuracy: 0.8622 - val_loss: 0.0907 - val_accuracy: 0.9681\n",
      "Epoch 175/200\n",
      "129/129 [==============================] - 82s 637ms/step - loss: 0.2456 - accuracy: 0.8731 - val_loss: 0.0986 - val_accuracy: 0.9632\n",
      "Epoch 176/200\n",
      "129/129 [==============================] - 82s 633ms/step - loss: 0.2406 - accuracy: 0.8757 - val_loss: 0.1039 - val_accuracy: 0.9662\n",
      "Epoch 177/200\n",
      "129/129 [==============================] - 82s 636ms/step - loss: 0.2481 - accuracy: 0.8653 - val_loss: 0.1290 - val_accuracy: 0.9565\n",
      "Epoch 178/200\n",
      "129/129 [==============================] - 82s 637ms/step - loss: 0.2484 - accuracy: 0.8696 - val_loss: 0.1107 - val_accuracy: 0.9623\n",
      "Epoch 179/200\n",
      "129/129 [==============================] - 82s 635ms/step - loss: 0.2466 - accuracy: 0.8643 - val_loss: 0.1136 - val_accuracy: 0.9700\n",
      "Epoch 180/200\n",
      "129/129 [==============================] - 82s 639ms/step - loss: 0.2428 - accuracy: 0.8729 - val_loss: 0.1007 - val_accuracy: 0.9691\n",
      "Epoch 181/200\n",
      "129/129 [==============================] - 82s 636ms/step - loss: 0.2307 - accuracy: 0.8868 - val_loss: 0.0883 - val_accuracy: 0.9603\n",
      "Epoch 182/200\n",
      "129/129 [==============================] - 82s 638ms/step - loss: 0.2406 - accuracy: 0.8738 - val_loss: 0.1144 - val_accuracy: 0.9603\n",
      "Epoch 183/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2473 - accuracy: 0.8701 - val_loss: 0.1312 - val_accuracy: 0.9526\n",
      "Epoch 184/200\n",
      "129/129 [==============================] - 83s 641ms/step - loss: 0.2280 - accuracy: 0.8848 - val_loss: 0.1118 - val_accuracy: 0.9613\n",
      "Epoch 185/200\n",
      "129/129 [==============================] - 82s 638ms/step - loss: 0.2458 - accuracy: 0.8699 - val_loss: 0.1109 - val_accuracy: 0.9623\n",
      "Epoch 186/200\n",
      "129/129 [==============================] - 82s 635ms/step - loss: 0.2448 - accuracy: 0.8760 - val_loss: 0.0943 - val_accuracy: 0.9652\n",
      "Epoch 187/200\n",
      "129/129 [==============================] - 83s 641ms/step - loss: 0.2423 - accuracy: 0.8708 - val_loss: 0.0833 - val_accuracy: 0.9691\n",
      "Epoch 188/200\n",
      "129/129 [==============================] - 82s 635ms/step - loss: 0.2393 - accuracy: 0.8755 - val_loss: 0.0890 - val_accuracy: 0.9691\n",
      "Epoch 189/200\n",
      "129/129 [==============================] - 81s 631ms/step - loss: 0.2591 - accuracy: 0.8638 - val_loss: 0.1289 - val_accuracy: 0.9720\n",
      "Epoch 190/200\n",
      "129/129 [==============================] - 82s 634ms/step - loss: 0.2410 - accuracy: 0.8768 - val_loss: 0.1091 - val_accuracy: 0.9652\n",
      "Epoch 191/200\n",
      "129/129 [==============================] - 81s 630ms/step - loss: 0.2517 - accuracy: 0.8661 - val_loss: 0.1108 - val_accuracy: 0.9662\n",
      "Epoch 192/200\n",
      "129/129 [==============================] - 82s 639ms/step - loss: 0.2422 - accuracy: 0.8677 - val_loss: 0.1044 - val_accuracy: 0.9691\n",
      "Epoch 193/200\n",
      "129/129 [==============================] - 82s 635ms/step - loss: 0.2376 - accuracy: 0.8721 - val_loss: 0.1039 - val_accuracy: 0.9720\n",
      "Epoch 194/200\n",
      "129/129 [==============================] - 81s 630ms/step - loss: 0.2483 - accuracy: 0.8713 - val_loss: 0.1005 - val_accuracy: 0.9749\n",
      "Epoch 195/200\n",
      "129/129 [==============================] - 82s 637ms/step - loss: 0.2388 - accuracy: 0.8788 - val_loss: 0.0987 - val_accuracy: 0.9662\n",
      "Epoch 196/200\n",
      "129/129 [==============================] - 82s 634ms/step - loss: 0.2431 - accuracy: 0.8764 - val_loss: 0.1033 - val_accuracy: 0.9720\n",
      "Epoch 197/200\n",
      "129/129 [==============================] - 83s 640ms/step - loss: 0.2328 - accuracy: 0.8864 - val_loss: 0.0984 - val_accuracy: 0.9700\n",
      "Epoch 198/200\n",
      "129/129 [==============================] - 82s 637ms/step - loss: 0.2369 - accuracy: 0.8769 - val_loss: 0.1016 - val_accuracy: 0.9691\n",
      "Epoch 199/200\n",
      "129/129 [==============================] - 82s 637ms/step - loss: 0.2248 - accuracy: 0.8884 - val_loss: 0.1270 - val_accuracy: 0.9662\n",
      "Epoch 200/200\n",
      "129/129 [==============================] - 83s 642ms/step - loss: 0.2344 - accuracy: 0.8799 - val_loss: 0.1183 - val_accuracy: 0.9613\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       519\n",
      "           1       0.94      0.99      0.96       515\n",
      "\n",
      "    accuracy                           0.96      1034\n",
      "   macro avg       0.96      0.96      0.96      1034\n",
      "weighted avg       0.96      0.96      0.96      1034\n",
      "\n",
      "[INFO] saving mask detector model...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f3fed49f8e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss and Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# convert the data and labels to NumPy arrays\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dense(64, activation=\"relu\")(headModel)\n",
    "headModel = Dense(32, activation=\"relu\")(headModel)\n",
    "headModel = Dense(16, activation=\"relu\")(headModel)\n",
    "headModel = Dense(8, activation=\"relu\")(headModel)\n",
    "headModel = Dense(4, activation=\"relu\")(headModel)\n",
    "\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)\n",
    "\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"TlMoBV3\", save_format=\"h5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "imagePathsSub = list(paths.list_images(\"./valImgs\"))\n",
    "dataSub = []\n",
    "datSubName=[]\n",
    "\n",
    "\n",
    "# loop over the image paths\n",
    "for imagePath in imagePathsSub:\n",
    "\t# extract the class label from the filename\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "\t# load the input image (224x224) and preprocess it\n",
    "\timage = load_img(imagePath, target_size=(224, 224))\n",
    "\timage = img_to_array(image)\n",
    "\timage = preprocess_input(image)\n",
    "\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdataSub.append(image)\n",
    "\tdatSubName.append(imagePath)\n",
    "    \n",
    "    \n",
    "dataSubC = np.array(dataSub, dtype=\"float32\")\n",
    "dataSubDF=pd.DataFrame({'datSubName':datSubName,'dataSub':dataSub})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSubDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxsSub = model.predict(dataSubC, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxsSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxsSubLab = np.argmax(predIdxsSub, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxsSubLab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datSubName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datSubNameTrimed=[]\n",
    "for el in datSubName:\n",
    "    NameTrimed=el.replace(\"./valImgs/\", \"\")\n",
    "    datSubNameTrimed.append(NameTrimed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datSubNameTrimed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df=pd.DataFrame({'image':datSubNameTrimed,'target':predIdxsSubLab})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('MaskSubTFL2000.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
